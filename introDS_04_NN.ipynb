{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"introDS_04_NN","provenance":[{"file_id":"1_vgP9zl5Vf-T4jgSmysXtmgvtGDXY5hU","timestamp":1624800083415},{"file_id":"11KUQq1tyj79LCTvH1Kfqrk94-R8YkO2W","timestamp":1624799623702}],"collapsed_sections":[],"authorship_tag":"ABX9TyMge4Mt8NcEVzznCphgTeRu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JbqYFULWXT3c"},"source":["# ニューラルネットワークを用いた手書き文字認識\n","\n","今回の演習では，ニューラルネットワークを利用した手書き文字認識を作成してみます．近年の研究では複雑なニューラルネットワークを大規模データを利用して学習することで，非常に高い識別性能が実現されています．今回の演習では，講義で学習した3層の基本的なニューラルネットワークを利用して，ニューラルネットワークがどのように文字認識を行っているかを確認してみます．"]},{"cell_type":"markdown","metadata":{"id":"eFjpuOnGnip6"},"source":["# 0. 今回利用する Python(numpy) の機能\n","\n","今回の演習で利用する Python の機能について説明します，プログラミングの詳細に興味がない場合は1まで飛ばしてください（ビデオでの説明もありません）"]},{"cell_type":"markdown","metadata":{"id":"1AUSIHJNr3y6"},"source":["## ベクトルの要素積\n","\n","ベクトルの要素積は以下のようにベクトル同士を掛けあわせることで計算できます．\n","今回は行ベクトル $ x = [1, 2, 3, 4, 5]$ を使って計算してみます．"]},{"cell_type":"code","metadata":{"id":"3hJ26gVRrhWZ"},"source":["# 0-1: ベクトルの要素積（アダマール積）\n","\n","import numpy as np\n","\n","x = np.array([[1,2,3,4,5]])\n","print(\"x * x = \", x * x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Z_qkgHvsaN1"},"source":["# スカラーとベクトルの計算\n","ベクトルとスカラーを足し合わせることで，すべての要素に値を足すことが可能です．"]},{"cell_type":"code","metadata":{"id":"VnAU1FPCsmHx"},"source":["# 0-2: ベクトルとスカラーの足し算\n","\n","print(\"x + 1 = \", x + 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-K4KYsxs_eO"},"source":["ベクトルでスカラーを割った場合も，要素ごとの割り算を行うことができます．"]},{"cell_type":"code","metadata":{"id":"tPwrmjNHniPd"},"source":["# 0-3: ベクトルとスカラーの割り算\n","\n","print(\"5.0 / x =\", 5.0/x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EsHedbc8tfiH"},"source":["行列，ベクトルの転置は x.T と記述することで，計算可能です．行ベクトルx は x.T により列ベクトルとなります．"]},{"cell_type":"code","metadata":{"id":"KKeY2VWwtvu-"},"source":["# 0-4: ベクトルの転置\n","\n","print(\"x^T = \", x.T)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e-0TYDBJunEG"},"source":["ベクトル・行列の一般的な積は @ で計算可能です．例えば，xどうしの内積(x,x)は以下で計算可能です．"]},{"cell_type":"code","metadata":{"id":"NIyJIMgYuvSN"},"source":["# 0-5: 行列・ベクトルの積\n","\n","print(\"(x,x) = \", x @ x.T)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BHP1A3asu-YM"},"source":["exp(x), 平方根などもまとめて計算可能です．"]},{"cell_type":"code","metadata":{"id":"5TirQ7PwvCOw"},"source":["# 0-6: いろいろな計算\n","\n","print(\"exp(x) =\", np.exp(x))\n","print(\"sqrt(x) = \", np.sqrt(x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T0tv3VamwGp4"},"source":["以上を踏まえてニューラルネットの学習を実装してみます．"]},{"cell_type":"markdown","metadata":{"id":"76G4Zr0xZGdZ"},"source":["# 1. 画像のデータの表現\n","手書き文字認識を実施するにあたり，手書き文字などの画像データがどのように表現されるか考えてみます．まずは，実際に手動（マウス）で文字を書いてみて，それがどのように表現されるか見てみましょう．"]},{"cell_type":"code","metadata":{"id":"QVormi0zHmO2","cellView":"form"},"source":["#@title 左の矢印（▷）を押して，下に表示される黒い枠の中にマウスで数字を書いてみてください．書き終わったら finish ボタンを押してください．\n","\n","from IPython.display import HTML\n","from io import BytesIO\n","from PIL import Image as Im\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","canvas_html = \"\"\"\n","<canvas width=%d height=%d></canvas>\n","<br>\n","<button>Finish</button>\n","<button id=\"clear\">Clear</button>\n","\n","<script>\n","var canvas = document.querySelector('canvas')\n","var ctx = canvas.getContext('2d')\n","ctx.lineWidth = %d\n","ctx.fillStyle = 'rgb(0,0,0)';\n","ctx.fillRect(0, 0, canvas.width, canvas.height);\n","ctx.strokeStyle = 'white';\n","\n","var button = document.querySelector('button')\n","var mouse = {x: 0, y: 0}\n","\n"," \n","\n","canvas.addEventListener('mousemove', function(e) {\n","  mouse.x = e.pageX - this.offsetLeft\n","  mouse.y = e.pageY - this.offsetTop\n","})\n","canvas.onmousedown = ()=>{\n","  ctx.beginPath()\n","  ctx.moveTo(mouse.x, mouse.y)\n","  canvas.addEventListener('mousemove', onPaint)\n","}\n","canvas.onmouseup = ()=>{\n","  canvas.removeEventListener('mousemove', onPaint)\n","}\n","var onPaint = ()=>{\n","  ctx.lineTo(mouse.x, mouse.y)\n","  ctx.stroke()\n","}\n","\n","clear.addEventListener(\"click\", function(){\n","  ctx.fillStyle = 'rgb(0,0,0)';\n","  ctx.fillRect(0, 0, canvas.width, canvas.height);\n","});\n","\n","var data = new Promise(resolve=>{\n","  button.onclick = ()=>{\n","    resolve(canvas.toDataURL('image/png'))\n","  }\n","})\n","</script>\n","\"\"\"\n","\n","width = 8\n","height = 8\n","\n","def draw(filename='drawing.png', w=160, h=160, line_width=30):\n","  display(HTML(canvas_html % (w, h, line_width)))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","  img = Im.open(BytesIO(binary))\n","  img = img.resize((width,height))\n","  img = img.convert('L')\n","\n","  return np.array(img,dtype=np.float)\n","\n","x = draw()\n","print(\"入力した画像は以下のとおりです\\n\", x)\n","N = x.shape[1] * x.shape[0]\n","print(\"グラフで表すとこうなります（列ベクトルで見づらいため，転置して行ベクトルとして表示しています）\\n\")\n","plt.imshow(x, cmap=\"gray\")\n","plt.show()\n","print(\"ベクトルで表現するとこうなります\\n\")\n","x = x.reshape([N,1])\n","print(\"x^T = \", x.T)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYTEoao3GAnz"},"source":["上記の通り，画像は小さなマス目に区切られており，それぞれのマス目（今回は8x8=64個のマス目）に明るさ（輝度）を設定することで構成されています．この明るさを数値により表現し，これを並べてベクトルとすることで解析が行われます．"]},{"cell_type":"markdown","metadata":{"id":"N6c9yTN9aIeC"},"source":["## 1.1 データの正規化\n","\n","しかし，画像をそのまま扱った場合，画像を取得した状況に応じてデータのばらつきが生じてしまいます．例としてノートに書かれた数字をカメラで撮影する場合を考えてみます．このような場合，たとえ同じ数字を撮影した場合でも，部屋が明るい場合には全体的に明るい画像（輝度が高い画像）が，暗い場合には暗い画像（輝度が低い画像）が撮影されることになります．このような明るさの影響によるデータのばらつきを抑制するための処理がデータの正規化です．データの正規化には様々な方法がありますが，明るさの平均が0, 分散が1となるように正規化してみます．このような正規化は，以下の式で実現できます．\n","\n","$ 平均：E(x) = \\frac{1}{N}\\sum_{j=1}^N x_i = {\\bf 1}^T {\\bf x} / N$\n","\n","$ 分散：\\sigma^2 = E(x)^2 - E(x^2) = \\frac{1}{N}\\sum_{j=1}^N x_j^2 - E(x)^2 = {\\bf x}^T {\\bf x} / N - E(x)^2 $\n","\n","$ 正規化された画像：{\\bf x}' = (x_i - E(x))/\\sqrt{\\sigma^2}$\n","\n","ここで，${\\bf x} = [x_1, x_2, \\cdots, x_N]^T$, $N$はマス目の個数（今回は64）です．\n","\n","### 問題１：このような正規化操作を実現するための関数を作成してみましょう"]},{"cell_type":"code","metadata":{"id":"zHUEKuILb4Ag"},"source":["# 1-1: データの正規化\n","\n","def normalize(x):\n","  one = np.ones(N) # one はすべての要素が1のベクトルです\n","\n","  ave = # 問題１−１：平均の計算\n","  var = # 問題１−２：分散の計算\n","  \n","  x_d = # 問題１−３：正規化されたベクトル x_d を計算\n","  return x_d\n","\n","# 値がどのように変化するか表示してみます．\n","print(\"正規化前\")\n","print(x.T)\n","print(\"正規化後\")\n","print(normalize(x).T)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n4Ke_C_oNPNP"},"source":["このような正規化を施すことで，文字識別を安定化させることができます．"]},{"cell_type":"markdown","metadata":{"id":"SRhWXd4_aLvd"},"source":["## 1.2 手書き数字データセットの読み込み\n","\n","文字認識を行うニューラルネットを構成するためには，手書き文字画像を大量に集める非強うがあります．今回はPython上にあらかじめ準備されたデータセットを利用します．\n","ここでは下のプログラムを実行してください（変更箇所はありません）．"]},{"cell_type":"code","metadata":{"id":"EPuzHCPSTP2H"},"source":["# 1-2: 手書き数字データの読み込み\n","import matplotlib.pyplot as plt\n","\n","from sklearn import datasets\n","digits = datasets.load_digits()\n","labels = digits.target\n","images = digits.images\n","# 10 個分のデータを表示する\n","for i in range(50):\n","  plt.subplot(5, 10, i+1)\n","  plt.axis(\"off\")\n","  plt.title(str(labels[i]))\n","  plt.imshow(images[i], cmap=\"gray\")\n","\n","plt.show()\n","print(\"画像の総数は\", images.shape[0], \"です．\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sFJTVsyAaUag"},"source":["# 2. ニューラルネットの作成と学習\n","## 2.1 ベクトル・行列による表現\n","\n","それでは，実際にニューラルネットワークの構成と学習を行っていきます．ニューラルネットの構成は講義資料に則って行いますが，ここではpythonによる実装を簡単にするためにベクトル行列を用いてそれぞれの計算を書き換えます．\n","\n","$ {\\bf u}_i = {\\bf w}_0 + W{\\bf x}_i $\n","\n","$ {\\bf z}_i = \\psi({\\bf u})_i$\n","\n","$ \\hat{y}_i = v_0 + {\\bf v}^T {\\bf z}_i$\n","\n","\n","ここで，${\\bf u}_i$, ${\\bf z}_i$，${\\bf v}_0$，$W$, $w_0$は以下のとおりです．\n","\n","${\\bf u}_i = [u_{1i}, \\cdots, c_{Ni}]^T$\n","\n","${\\bf z}_i = [z_{1i}, \\cdots, z_{Ni}]^T$\n","\n","${\\bf v}_i = [v_{1i}, \\cdots, v_{Ki}]^T$\n","\n","$W = \n","\\left [\n","\\begin{array}{ccc}\n","w_{11} & \\cdots & w_{1N}\\\\\n","& \\ddots & \\\\\n","w_{M1} & \\cdots & w{KN}\n","\\end{array}\n","\\right ]\n","$\n","\n","$ {\\bf w}_0 = [w_{01}, \\cdots, w_{0N}]^T$ \n","\n","$K$は中間層のノードの数です．\n","\n","$\\hat{y}_i$がニューラルネット全体の出力であり，今回はこの出力が画像に描かれた数字と一致するようにニューラルネットを学習します．画像に描かれた数字が教師データ$y_i$として得られているとし，その誤差$E$を以下のように定義します．\n","\n","$E = \\sum_{i=1}^K (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^K e_i^2$\n","\n","講義資料のとおり，ニューラルネットの学習はこの誤差$E$を最小とする$W$, ${\\bf w}_0$, ${\\bf v}$, $v_0$を求めることに相当します．\n","\n","まずは，これらの値を入れておくための行列，ベクトルを準備します（ひとまず変更箇所はありません）．"]},{"cell_type":"code","metadata":{"id":"uAJIUQOnanS2"},"source":["# 2-1: データの初期化，中間層のノード数を変更する場合は以下を変更して実行\n","\n","K = 10 # 中間層のノード数\n","\n","# 入力層と中間層の接続に関するパラメタ\n","w0 = np.random.rand(K,1)\n","W = np.random.rand(K, N)\n","\n","# 中間層と出力層の接続に関するパラメタ\n","v = np.random.rand(K,1)\n","v0 = np.random.rand()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DZNn1PPxbWDM"},"source":["これらの行列ベクトルにはひとまずランダムな値を入れておき，これを学習により最適化していきます．"]},{"cell_type":"markdown","metadata":{"id":"iaKTjSC9b_Hy"},"source":["## 2.2 非線形関数\n","\n","次に，非線形関数としてシグモイド関数を準備します．講義資料にあるとおりシグモイド関数は以下のように定義されています．\n","\n","$\\psi(z) = \\frac{1}{1+\\exp(-z)}$\n","\n","### 問題２：シグモイド関数を作成してください．"]},{"cell_type":"code","metadata":{"id":"e4FUBbh6bVmo"},"source":["# 2-2: 非線形関数（シグモイド関数）\n","\n","def sigmoid(z):\n","  psi =　# 問題２：psi(z) の計算結果を psi に代入します．\n","  return psi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JRt0WHcmk_-L"},"source":["## 2.3 順方向計算の作成\n","\n","再度の記述となりますが，$y_i$は以下のように計算されます．\n","\n","$ {\\bf u}_i = {\\bf w}_0 + W{\\bf x}_i $\n","\n","$ {\\bf z}_i = \\psi({\\bf u})_i$\n","\n","$ \\hat{y}_i = v_0 + {\\bf v}^T {\\bf z}_i$\n","\n","\n","### 問題３：それではこれらを使ってまず順伝播（入力${\\bf x}_i$から$y_i$を計算するプロセス）を作成しましょう．"]},{"cell_type":"code","metadata":{"id":"PvK5rcWTk_dY"},"source":["# 2-3: 順方向の計算\n","\n","def forward_prop(v0, v, w0, W, x_i):\n","  u_i =   # 問題３−１：入力 x_i から u_i を計算\n","  z_i =   # 問題３−２：シグモイド関数により z_iを計算\n","  yh_i =  # 問題３−３：yh_i を計算\n","\n","  return yh_i, z_i"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w-mW4jhvmK0J"},"source":["## 2.4 逆方向計算の作成\n","\n","次に，評価関数$E$の微分結果を逆方向に反映させていくことで，それぞれの変数に関する微分を計算してみます．\n","\n","この計算では，$\\frac{\\partial E}{\\partial W}$などを計算する必要がありますが，これらは以下のように$\\frac{\\partial e_i}{\\partial W}$の総和として計算できます．\n","\n","$ \\frac{\\partial E}{\\partial W} = \\sum_{i=1}^n \\frac{\\partial e_i}{\\partial W}$\n","\n","$ \\frac{\\partial E}{\\partial {\\bf v}} = \\sum_{i=1}^n \\frac{\\partial e_i}{\\partial {\\bf v}}$\n","\n","そのため，まずは各変数の$e_i$に関する微分を計算します．講義資料のとおり，これらは以下のように計算できます．\n","\n","$\\frac{\\partial e_i}{\\partial v_0} = -2 (y_i - \\hat{y}_i)$\n","\n","$\\frac{\\partial e_i}{\\partial {v}_k} = -2 (y_i - \\hat{y}_i) z_{ik}$\n","\n","これは，以下のようにまとめることができます．\n","\n","$\n","\\frac{\\partial e_i}{\\partial {\\bf v}} = \n","\\left [\n","\\begin{array}{c}\n","\\frac{\\partial e_i}{\\partial {v}_1} \\\\ \n","\\vdots \\\\\n","\\frac{\\partial e_i}{\\partial {v}_K}\n","\\end{array}\n","\\right ]\n","=\n","\\left [\n","\\begin{array}{c}\n","\\frac{\\partial e_i}{\\partial v_0} z_{i1}\\\\\n","\\vdots\\\\\n","\\frac{\\partial e_i}{\\partial v_0} z_{iK}\n","\\end{array}\n","\\right ]\n","= \\frac{\\partial e_i}{\\partial v_0} {\\bf z}_i\n","$\n","\n","また，${w}_{k0}$については以下のように計算できます．\n","\n","$ \\frac{\\partial e_i}{\\partial w_{k0}} = -2 (y_i - \\hat{y}_i) v_k \\psi(u_{ik}) (1 - \\psi(u_{ik})) = \\frac{\\partial e_i}{\\partial {v}_k}v_k(1-z_{ik})$\n","\n","これは以下のようにまとめられます．\n","\n","$\n","\\frac{\\partial e_i}{\\partial {\\bf w}_0} = \n","\\left [\n","  \\begin{array}{c}\n","  \\frac{\\partial e_i}{\\partial w_{10}} \\\\ \\vdots \\\\ \\frac{\\partial e_i}{\\partial w_{K0}}\n","  \\end{array}\n","\\right ]\n","=\n","\\left [\n","  \\begin{array}{c}\n","  \\frac{\\partial e_i}{\\partial {v}_1}v_k(1-z_{i1}) \\\\ \\vdots \\\\\n","  \\frac{\\partial e_i}{\\partial {v}_K}v_k(1-z_{iK})\n","  \\end{array}\n","\\right ]\n"," = \\frac{\\partial e_i}{\\partial {\\bf v}} \\circ {\\bf v} \\circ ({\\bf 1} - {\\bf z})\n","$\n","\n","ここで，$\\circ$はベクトルの要素ごとの積を表します．\n","\n","同様に${w}_{kj}$についても以下のように計算できます．\n","\n","$ \\frac{\\partial e_i}{\\partial w_{kj}} = -2 (y_i - \\hat{y}_i) v_k \\psi(u_{ik}) (1 - \\psi(u_{ik}))x_{ij} = \\frac{\\partial e_i}{\\partial w_{k0}}x_{ij}$\n","\n","これは，以下のようにまとめることができます．\n","\n","$\\frac{\\partial e_i}{\\partial W} =\n","\\left [\n","\\begin{array}{ccc}\n","\\frac{\\partial e_i}{\\partial w_{11}} & \\cdots & \\frac{\\partial e_i}{\\partial w_{1N}}\\\\\n","&  \\ddots & \\\\\n","\\frac{\\partial e_i}{\\partial w_{K1}} & \\cdots & \\frac{\\partial e_i}{\\partial w_{KN}}\n","\\end{array}\n","\\right ]\n","=\n","\\left [\n","  \\begin{array}{ccc}\n","  \\frac{\\partial e_i}{\\partial {\\bf w}_0} x_{i1} & \n","  \\cdots & \n","  \\frac{\\partial e_i}{\\partial {\\bf w}_0} x_{iN} \n","  \\end{array}\n","\\right ] = \n","\\frac{\\partial e_i}{\\partial {\\bf w}_0} {\\bf x}_i^T\n","$\n","\n","以上をまとめると，各変数の微分は以下のように計算できます．\n","\n","$\\frac{\\partial e_i}{\\partial v_0} = -2 (y_i - \\hat{y}_i)\\\\\n","\\frac{\\partial e_i}{\\partial {\\bf v}} = \\frac{\\partial e_i}{\\partial v_0} {\\bf z}_i\\\\\n","\\frac{\\partial e_i}{\\partial {\\bf w}_0} = \\frac{\\partial e_i}{\\partial {\\bf v}} \\circ {\\bf v} \\circ ({\\bf 1} - {\\bf z})\\\\\n","\\frac{\\partial e_i}{\\partial W} =\n","\\frac{\\partial e_i}{\\partial {\\bf w}_0} {\\bf x}_i^T\n","$\n","\n","### 問題４：それでは逆方向の計算を実装してみましょう．"]},{"cell_type":"code","metadata":{"id":"sE9XiL4fpoKV"},"source":["# 2-4: 逆方向の計算（誤差逆伝播）\n","\n","def back_prop(yh_i, y_i, v, z_i, x_i,):\n","  dy_i =  # 問題４−１：de_i / dy_i \n","  dv0_i = # 問題４−２：de_i / dv_0\n","  dv_i =  # 問題４−３：de_i / dv\n","  dw0_i = # 問題４−４：de_i / dw0\n","  dW_i =  # 問題４−５：de_i / dW\n","\n","  return dv0_i, dv_i, dw0_i, dW_i"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ft3v6psjWj6C"},"source":["## 2.5 $E$に関する微分の計算\n","\n","これで，$i$番目の画像に対する評価値$e_i$に関する微分を計算することができました．次はこれらの総和を計算することで，全体の評価関数$E$に対する微分を計算してみましょう．\n","\n","### 問題５：$e_i$の微分の総和から，$E$の微分を計算しましょう．"]},{"cell_type":"code","metadata":{"id":"hCF11KhdW9xD"},"source":["# 2-5: 評価関数全体の微分の計算\n","\n","def derivative_E(images, labels, data_num, v0, v, w0, W):\n","  # 微分の累積を 0 にセット\n","  dv0 = 0\n","  dv = np.zeros([K,1])\n","  dw0 = np.zeros([K,1])\n","  dW = np.zeros([K, N])\n","\n","  for i in range(data_num):\n","    # 画像をベクトルに変形\n","    x_i = np.array(images[i],dtype=np.float).reshape(N,1)\n","    # 正規化\n","    x_i = normalize(x_i)\n","    # ラベルを取得\n","    y_i = labels[i]\n","    # 順方向計算（先ほど作成した関数により計算）\n","    yh_i, z_i = forward_prop(v0, v, w0, W, x_i)\n","    # 逆方向計算（先ほど作成した関数により計算）\n","    dv0_i, dv_i, dw0_i, dW_i = back_prop(yh_i, y_i, v, z_i, x_i)\n","\n","    # 問題５：以下を完成させてそれぞれの微分値を計算せよ．\n","    dv0 = # 問題５−１：dv0_i の総和から dv0を計算\n","    dv =  # 問題５−２：dv の総和から dv を計算\n","    dw0 = # 問題５−３：dw0_i の総和から dw0 を計算\n","    dW =  # 問題５−４：dW_i の総和から dW を計算\n","\n","  return dv0, dv, dw0, dW"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wPY3gd_4ZjNP"},"source":["## 2.6 性能チェック機能の作成\n","\n","これで，ニューラルネットの学習を行うための準備が整いました．これからこれらを利用して繰り返し計算によりニューラルネットワークの学習を行っていきます．ただし，このような学習を行う場合，どこまで学習がすすんだかを確認するため，ニューラルネットの状態をチェックするための機能が必要となります．そこで，現在のパラメタ(${\\bf w}_0, W, v_o, {\\bf v})と画像データから誤差の総和および現在の正解率（数字が正しく認識される割合）を計算する関数を作成します．"]},{"cell_type":"code","metadata":{"id":"TemlVDcObPGI"},"source":["# 2-6: 性能チェック関数\n","\n","def neuralnet_exam(images, labels, start, num, v0, v, w0, W):\n","  # ラベルと出力の2乗誤差の総和\n","  err = 0\n","  # 正しく識別あ行われた総数\n","  correct = 0\n","\n","  for i in range(start, start + num):\n","    x_i = normalize(np.array(images[i],dtype=np.float).reshape(N,1))\n","    yh_i, z_i = forward_prop(v0, v, w0, W, x_i)\n","    err += (yh_i - labels[i])**2\n","    if (abs(labels[i] - yh_i) < 0.5):\n","      correct+=1\n","  return err, correct"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T04QI9mzcj1o"},"source":["これで，現在の学習状態をチェックすることが可能となりました．"]},{"cell_type":"markdown","metadata":{"id":"FpjOC6oictbm"},"source":["# 3 ニューラルネットの学習とテスト\n","\n","## 3.1 学習プログラムの作成\n","それでは，$W$等のパラメタを微分値を用いて更新することで，ニューラルネットの学習を行いましょう．講義資料にあるとおり，これらのパラメタは以下のように更新されます．\n","\n","$ \n","\\left [\n","  \\begin{array}{c}\n","  {v_0^{t+1}} \\\\ {\\bf v}^{t+1} \\\\ {\\bf w}_0^{t+1} \\\\ W^{t+1}\n","  \\end{array}\n","\\right ]\n","\\left [\n","  \\begin{array}{c}\n","  {v_0^{t}} \\\\ {\\bf v}^{t} \\\\ {\\bf w}_0^{t} \\\\ W^{t}\n","  \\end{array}\n","\\right ]\n","  -\n","\\alpha_t\n","\\left [\n","  \\begin{array}{c}\n","  \\frac{\\partial E}{\\partial v_0^{t}} |_{(W, {\\bf v}) = (W^t, {\\bf v}^t)} \\\\ \n","  \\frac{\\partial E}{\\partial {\\bf v^{t}}} |_{(W, {\\bf v}) = (W^t, {\\bf v}^t)}\\\\ \n","  \\frac{\\partial E}{{\\partial \\bf w}_0^{t}} |_{(W, {\\bf v}) = (W^t, {\\bf v}^t)} \\\\ \n","  \\frac{\\partial E}{\\partial W^{t}}|_{(W, {\\bf v}) = (W^t, {\\bf v}^t)}\n","  \\end{array}\n","\\right ]\n","$\n","\n","$\\alpha$は更新に応じて変更する方法などもありますが，今回は固定の値として0.25 / （学習に用いるデータの数）を利用します（データ数で割っている理由は，データの数が大きくなると，微分の総和も大きくなるためです）．\n","### 問題６：下記のプログラムのパラメタ更新部分を作成して実行することで，どのように学習が進むか確認してみましょう（5000回のパラメタ更新を行うため，プログラムの実行には数分かかります，学習終了が表示されるまで待ってください）"]},{"cell_type":"code","metadata":{"id":"uq2pobggUqVw"},"source":["# 3-1: ニューラルネットの学習\n","\n","# 学習に用いるデータの数\n","data_num = 1000\n","\n","# 更新のステップ幅（学習率などとも呼ばれる）\n","alpha = 0.1 / data_num\n","# 繰り返し回数，今回は5000回\n","T = 5000\n","num = int(T/100)\n","\n","# 誤差の変化を記録しておくための配列\n","err_train = np.zeros(num,dtype=np.float)\n","err_test = np.zeros(num,dtype=np.float)\n","cor_train = np.zeros(num,dtype=np.float)\n","cor_test = np.zeros(num,dtype=np.float)\n","\n","for t in range (T):\n","  err = 0\n","  correct = 0\n","  num = int(T/100)\n","\n","  # 各パラメタの微分を計算\n","  dv0, dv, dw0, dW = derivative_E(images, labels, data_num , v0, v, w0, W)\n","\n","  # 問題６：alpha と微分結果を使って各パラメタを更新しましょう（足し算ではなく引き算になることに注意してください）\n","  v0 = # 問題６−１：v0をalphaとdv0を使って更新\n","  v =  # 問題６−２：vをalphaとdvを使って更新\n","  w0 = # 問題６−３：w0をalphaとdw0を使って更新\n","  W =  # 問題６−４：WをalphaとdWを使って更新\n","\n","  # 100回に1回性能をチェック\n","  if ((t+1) % 100 == 0):\n","    # 訓練データでチェック\n","    p = int(t/100)\n","    err_train[p], cor_train[p] = neuralnet_exam(images, labels, 0, 100, v0, v, w0, W)\n","    # 検証用データでチェック\n","    err_test[p], cor_test[p] = neuralnet_exam(images, labels, 1000, 100, v0, v, w0, W)\n","\n","    print(\"loop = \", t+1, \"error = \",err_train[p], err_test[p],\"accuracy = \", cor_train[p], cor_test[p])\n","print(\"学習が終了しました\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WRmchEnVchcT"},"source":["学習が終了したら，下のプログラムを実行して誤差の遷移をグラフとして表示してみましょう（変更箇所はありません）"]},{"cell_type":"code","metadata":{"id":"itjiCnhBu3dE"},"source":["# 3-1-2: 学習遷移の表示\n","\n","# 誤差の遷移を表示する\n","plt.figure()\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"error\")\n","plt.plot(np.arange(50), err_train)\n","plt.plot(np.arange(50), err_test)\n","\n","# 認識率の遷移を表示する．\n","plt.figure()\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.ylim(0,100)\n","plt.plot(np.arange(50), cor_train)\n","plt.plot(np.arange(50), cor_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y_U_QTuwrKIc"},"source":["学習が終わると２つのグラフが表示されたはずです．１つ目のグラフは訓練データ（オレンジ），テストデータ（青）それぞれに対する誤差の遷移を表しており，グラフが下（0）に近づくほど誤差が小さくなっていることを表しています．もうひとつは識別性能の遷移を表しており，上（100%）に近づくほど高い性能を示しています．\n","グラフを見るとわかりますが，どちらのグラフについても訓練データよりもテストデータの方が悪い値となっていることがわかります．これは，ニューラルネットが訓練データに対して最適化されているため，これに含まれないデータに対しては性能が低下してしまうためです．このような現象は過学習と呼ばれます．これは，学習に用いるデータの数や学習するパラメタの数（中間層の層数やノード数）により変化しますが，一般的に学習データの数を増加させ，また，全体のパラメタ数を減少させることでその影響を軽減させられることがわかっています．\n","\n","なお，上のプログラム（3-1）を再度実行することで，続きから学習を行うことができます．パラメタが十分に学習されていない場合はこれにより性能を高められることもありますが，パラメタの数（K）が大きい場合には過学習が発生しやすくなります．\n","\n","\n","## 3.2 パラメタ数の学習への影響\n","\n","### 問題7：パラメタを変更しての再実行（下の手書き文字認識を実行したあとに行ってください）\n","\n","それではパラメタの数を変化させてみて，実際に学習結果がどのように変化するか確認してみましょう．中間層のノード数は「2-1:データの初期化」のKの値で設定されていますので，これを異なる数字に変化させて再度学習を行ってみましょう（Kの値を変更したあと，順番に各ブロックを実行してください）．\n","なお，K=10（初期設定）の場合の結果も提出してもらいますので，再度学習を行う前にグラフと識別結果は撮影しておいてください．\n"]},{"cell_type":"markdown","metadata":{"id":"cTvyiEzlqfu6"},"source":["# 4. 手書き文字認識\n","\n","最後に実際にマウスで文字を書いて手書き文字認識を行ってみましょう"]},{"cell_type":"code","metadata":{"cellView":"form","id":"Vm0JP9oupYAh"},"source":["#@title 左の矢印▷を押して出てくる四角にマウスで数字を書いて認識してみましょう（再実行したい場合は，再度▷を押してください）\n","canvas_html = \"\"\"\n","<canvas width=%d height=%d></canvas>\n","<br>\n","<button>Finish</button>\n","<button id=\"clear\">Clear</button>\n","\n","<script>\n","var canvas = document.querySelector('canvas')\n","var ctx = canvas.getContext('2d')\n","ctx.lineWidth = %d\n","ctx.fillStyle = 'rgb(0,0,0)';\n","ctx.fillRect(0, 0, canvas.width, canvas.height);\n","ctx.strokeStyle = 'white';\n","\n","var button = document.querySelector('button')\n","var mouse = {x: 0, y: 0}\n","\n"," \n","\n","canvas.addEventListener('mousemove', function(e) {\n","  mouse.x = e.pageX - this.offsetLeft\n","  mouse.y = e.pageY - this.offsetTop\n","})\n","canvas.onmousedown = ()=>{\n","  ctx.beginPath()\n","  ctx.moveTo(mouse.x, mouse.y)\n","  canvas.addEventListener('mousemove', onPaint)\n","}\n","canvas.onmouseup = ()=>{\n","  canvas.removeEventListener('mousemove', onPaint)\n","}\n","var onPaint = ()=>{\n","  ctx.lineTo(mouse.x, mouse.y)\n","  ctx.stroke()\n","}\n","\n","clear.addEventListener(\"click\", function(){\n","  ctx.fillStyle = 'rgb(0,0,0)';\n","  ctx.fillRect(0, 0, canvas.width, canvas.height);\n","});\n","\n","var data = new Promise(resolve=>{\n","  button.onclick = ()=>{\n","    resolve(canvas.toDataURL('image/png'))\n","  }\n","})\n","</script>\n","\"\"\"\n","\n","width = 8\n","height = 8\n","\n","def draw2(filename='drawing.png', w=160, h=160, line_width=30):\n","  display(HTML(canvas_html % (w, h, line_width)))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","  img = Im.open(BytesIO(binary))\n","  img = img.resize((width,height))\n","  img = img.convert('L')\n","\n","  return np.array(img,dtype=np.float)\n","\n","x = draw()\n","plt.imshow(x, cmap=\"gray\")\n","plt.show()\n","y_i, z_i = forward_prop(v0, v, w0, W, normalize(x.reshape(N,1)))\n","print(\"識別結果は\",y_i,\"です\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vjMpl8Zmqscv"},"source":["うまく認識できましたか？今回は非常に基本的な構造を持つニューラルネットワークを利用しているため，そこまで高い識別性能は実現できていません．しかし，現在はより高精度に認識を行うために様々な研究が行われており，非常に高い識別性能を持つニューラルネットワークも実現されています．興味があればそれらについても調べてみると良いでしょう．\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cpwFDjW2vKT5"},"source":["お疲れ様でした，以上で今回の演習は終了です．以下の内容を提出してください．\n","1. K = 10 とした場合の誤差と正解率の遷移のグラフを撮影して提出してください．\n","2. K の値を 10 より大きい値（例えば5），10より大きい値（例えば20）のそれぞれに変化させ，それぞれの場合の誤差，正解率の遷移の変化を撮影して提出してください．提出する際に，Kの値を下記のレポートに記述してください\n","3. 2で利用したKの値とそれぞれの場合の結果について，なぜそのような結果になったか考察し，それをレポートに手書きしたものを撮影して提出してください．\n"]}]}